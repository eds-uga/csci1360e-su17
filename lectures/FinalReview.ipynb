{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Final Exam Review\n",
    "\n",
    "CSCI 1360E: Foundations for Informatics and Analytics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Material"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Anything in *all lectures* is fair game!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Anything in *all assignments* is fair game!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - ...but there will be a *heavy preference* for everything after the midterm!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Science\n",
    " - Definition\n",
    " - Intrinsic interdisciplinarity\n",
    " - \"Greater Data Science\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Python Language\n",
    " - Philosophy\n",
    " - Compiled vs Interpreted\n",
    " - Variables, literals, types, operators (arithmetic and comparative)\n",
    " - Casting, typing system\n",
    " - Syntax (role of whitespace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data Structures\n",
    " - Collections (lists, sets, tuples, dictionaries)\n",
    " - Iterators, generators, and list comprehensions\n",
    " - Loops (`for`, `while`), loop control (`break`, `continue`), and utility looping functions (`zip`, `enumerate`)\n",
    " - Variable unpacking\n",
    " - Indexing and slicing\n",
    " - Differences in indexing between collection types (tuples versus sets, lists versus dictionaries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Conditionals\n",
    " - `if` / `elif` / `else` structure\n",
    " - Boolean algebra (stringing together multiple conditions with `or` and `and`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exception handling\n",
    " - `try` / `except` structure, and what goes in each block"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Functions\n",
    " - Defining functions\n",
    " - Philosophy of a function\n",
    " - Defining versus calling (invoking) a function\n",
    " - Positional (required) versus default (optional) arguments\n",
    " - Keyword arguments\n",
    " - Functions that take any number of arguments\n",
    " - Object references, and their behaviors in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "NumPy\n",
    " - Importing external libraries\n",
    " - The NumPy `ndarray`, its properties (`.shape`), and indexing\n",
    " - NumPy submodules\n",
    " - Vectorized arithmetic in lieu of explicit loops\n",
    " - NumPy array dimensions, or *axes*, and how they relate to the `.shape` property\n",
    " - Array broadcasting, uses and rules\n",
    " - Fancy indexing with boolean and integer arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "File I/O\n",
    " - Reading from / writing to files\n",
    " - Gracefully handling file-related errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Linear Algebra\n",
    " - Vectors and matrices\n",
    " - Dot products and matrix multiplication\n",
    " - Dimensions of *data* versus dimensionality of *NumPy arrays*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Probability and Statistics\n",
    " - Axioms of Probability\n",
    " - Dependence and independence\n",
    " - Conditional probability\n",
    " - Bayes' Theorem\n",
    " - Probability distributions\n",
    " - First-, second-, and higher-order statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Data Visualization and Exploration\n",
    " - Plotting data (line plots, scatter plots, histograms)\n",
    " - Plotting images, or matrices *as* images (colormaps)\n",
    " - Strategies for visualizing data of different dimensions\n",
    " - Accounting for missing data\n",
    " - Matplotlib, pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Natural Language Processing\n",
    " - Bag of words model\n",
    " - Preprocessing (stop words, stemming)\n",
    " - TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Image Processing\n",
    " - Pixel representation (RGB, grayscale)\n",
    " - Thresholding\n",
    " - Convolutional filters (blurring and sharpening)\n",
    " - Segmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Machine Learning\n",
    " - Supervised versus unsupervised learning\n",
    " - Classification algorithms (KNN, SVM)\n",
    " - Clustering algorithms (K-means, Spectral)\n",
    " - Bias-variance trade-off\n",
    " - Cross-validation\n",
    " - Training and testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Open Data Science\n",
    " - Pillars of Open Science\n",
    " - Anatomy of an open source project\n",
    " - Importance of licensing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Final Exam Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The format will be just like the midterm. That is to say: very close to that of JupyterHub assignments (there may or may not be autograders to help)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It will be **180 minutes**. Don't expect any flexibility in this time limit, so plan accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - You are **NOT** allowed to use internet resources or collaborate with your classmates (enforced by the honor system), but you **ARE** allowed to use lecture and assignment materials from this course, as well as terminals in the JupyterHub environment or on your local machine."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - I will be available on Slack for questions most of the day tomorrow, from 9am until about 3pm (then will be back online around 4pm until 5pm). Shoot me a direct message if you have a conceptual / technical question relating to the final, and I'll do my best to answer ASAP."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## JupyterHub Logistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - The final will be released on JupyterHub at **12:00am on Friday, July 28**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It will be collected at **12:00am on Saturday, July 29**. The release and collection will be done by automated scripts, so believe me when I say there won't be any flexibility on the parts of these mechanisms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Within that 24-hour window, you can start the exam (by \"Fetch\"-ing it on JupyterHub) whenever you like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **ONCE YOU FETCH THE FINAL, YOU WILL HAVE 180 MINUTES--3 HOURS--FROM THAT MOMENT TO SUBMIT THE COMPLETED FINAL BACK.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Furthermore, it's **up to you** to keep track of that time. Look at your system clock when you click \"Fetch\", or use the timer app on your smartphone, to help you track your time use. Once the 180 minutes are up, the exam is considered late."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    " - In theory, this should allow you to take the final when it is most convenient for you. Obviously you should probably start no later than 9:00PM on Friday, since any submissions after midnight will be considered late, even if you started at 11:58PM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Tough Assignment Questions and Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do not as I say, and not as I do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, for some reason, a lot of people outright ignored directions on this homework and lost points as a result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Part A, you computed the dot product of two arrays. Some people used loops; this was both explicitly disallowed in the directions, *and* it's more work than using NumPy array broadcasting!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def dot(arr1, arr2):\n",
    "    if arr1.shape[0] != arr2.shape[0]:\n",
    "        return None\n",
    "    p = arr1 * arr2  # Multiplies corresponding elements of the two arrays...no loops needed!\n",
    "    s = p.sum()      # Computes the sum of all the elements...still no loops needed!\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Another example is Part G, asking you to write a function that reverses the elements of an array. According to the instructions, you were **not allowed** to use either the `[::-1]` notation, or the `.reversed()` function. Doing so anyway means you missed this bit of `range` cleverness:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that `range` can take up to three arguments: a starting point, an ending point, and an increment. 99% of the time, you're starting at 0 and incrementing by 1, so the only argument you ever really give it is the length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if you think about it, you could use this to *start* at the *end*, *end* at the *start*, and *increment by -1*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even cooler: you could turn this `range` object into a list of indices, and then use that to *fancy index* the original array, effectively reversing it in one step. Observe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def reverse_array(arr):\n",
    "    start = arr.shape[0] - 1  # We're STARTING at the END\n",
    "    stop = -1  # Recall that range() always stops at \"index - 1\"\n",
    "    step = -1  # Since we start at the end, we increment by -1\n",
    "    \n",
    "    # np.arange is the same as range(), just auto-returns a NumPy array\n",
    "    # You could use range() here, too; you'd have to wrap it in list()\n",
    "    indices = np.arange(start, stop, step)\n",
    "    print(indices)\n",
    "    \n",
    "    reversed = arr[indices]    # Literally just...fancy index.\n",
    "    return reversed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4 3 2 1 0]\n",
      "Before reversal:  [10 20 30 40 50]\n",
      "After reversal:  [50 40 30 20 10]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "before = np.array([10, 20, 30, 40, 50])\n",
    "after = reverse_array(before)\n",
    "print(\"Before reversal: \", before)\n",
    "print(\"After reversal: \", after)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Polite `import`s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This isn't technically an error, but rather a very strong convention. Whenever you are importing modules, these imports should **all go in one place: the very top of the file.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a common tendency to have import statements inside of functions. This won't cause problems in terms of bugs, but does get very, very confusing if you're dealing with more than 1 function. After all, if you `import numpy as np` inside of one function, it may or may not be available in another function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, rather than try to figure out if you need to import NumPy over and over in every single function... just do all your `import` statements once at the very top of your program."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### `try/except` overenthusiasm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's great to see you know when to use `try/except` blocks! However--and this is very common--there's such as thing as *too much* use of these blocks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's what happens if you put too much of your code inside a `try` block: it **catches, and therefore effectively HIDES, errors and bugs in your code that have nothing to do with the errors you're trying to handle gracefully.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Two guidelines for using `try/except` blocks:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Keep the amount of code under a `try` statement to an *absolute minimum*. For example, if you're reading from a file, put only the calls to `open()` and `read()` inside the `try` block."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - *Always* give an error *type* that you're trying to handle; that way, if an unexpected error of a different type crops up, the block won't inadvertently hide it. It's easy enough to simply say `except:`, but I strongly urge you to specify the error type you're trying to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "One final note here: **please, please, please, do not EVER nest `try/except` statements.** This will only multiply the problems I've described. If you're trying to handle multiple types of errors, use multiple `except` statements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A6 (but also A3, so this is copy/pasted from the Midterm Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`if` statements don't always need an `else`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "I saw this a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def list_of_positive_indices(numbers):\n",
    "    indices = []\n",
    "    for index, element in enumerate(numbers):\n",
    "        if element > 0:\n",
    "            indices.append(index)\n",
    "        else:\n",
    "            pass  # Why are we here? What is our purpose? Do we even exist?\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "`if` statements are adults; they can handle being short-staffed, as it were. If there's literally nothing to do in an `else` clause, you're perfectly able to omit it entirely:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def list_of_positive_indices(numbers):\n",
    "    indices = []\n",
    "    for index, element in enumerate(numbers):\n",
    "        if element > 0:\n",
    "            indices.append(index)\n",
    "    return indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A7 (but also A4, so this is copy/pasted from the Midterm Review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**`len(ndarray)` versus `ndarray.shape`**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the question about checking that the lengths of two NumPy arrays were equal, a lot of people chose this route:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Some test data\n",
    "import numpy as np\n",
    "x = np.random.random(10)\n",
    "y = np.random.random(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which works, but only for *one-dimensional arrays*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "For anything other than 1-dimensional arrays, things get problematic:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.random((5, 5))  # A 5x5 matrix\n",
    "y = np.random.random((5, 10))  # A 5x10 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x) == len(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These definitely are **not** equal in length. But that's because `len` doesn't measure *length* of matrices...it only measures the number of rows (i.e., the first axis--which in this case is 5 in both, hence it thinks they're equal)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "You definitely want to get into the habit of using the `.shape` property of NumPy arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = np.random.random((5, 5))  # A 5x5 matrix\n",
    "y = np.random.random((5, 10))  # A 5x10 matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape == y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the answer we expect."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### The dangers of `in`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [2985, 42589, 13, 574, 57425, 574]\n",
    "\n",
    "225 in l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The keyword `in` is a great tool for testing if some value is present in a collection. But it has a potential downside."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Think of it this way: how would you implement `in` yourself? Probably something like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def in_function(haystack, needle):\n",
    "    for item in haystack:\n",
    "        if item == needle:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "h1 = [10, 20, 30, 40, 50]\n",
    "n1 = 20\n",
    "print(in_function(h1, n1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "n2 = 60\n",
    "print(in_function(h1, n2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Note that this function **requires a loop**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here, then, is the danger: if you're searching for a specific item in a *very large collection*, this can take awhile. Even more dangerous if you're running this search *inside of another loop*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This created a few failed autograder tests in A7, because JupyterHub automatically kills a test if it takes too long. It's entirely possible your code was correct in theory--and I tried to distribute points accordingly--but it nonetheless lost you points at first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Something to keep in mind: if you're already using a loop, chances are you probably don't need to use `in`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Dependent or Independent?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The question related to coin flips--two random variables $X$ and $Y$, counting the number of heads and tails, respectively--confused a lot of folks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Several said they were independent variables because \"each coin flip is an independent event.\" That is true, but it is the correct answer **to the wrong question.** The question isn't if each coin flip is independent, but if the number heads and tails in 1000 flips are independent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say, out of 1000 flips, you observed 600 heads, so you know $X = 600$. Does this give you any information about $Y$, the number of tails?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Oh yes: you know immediately that $Y = 400$.** This is the very definition of **dependent variables**: if you can directly compute one from the other, that means knowing one gives you information about the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features, features everywhere"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was a *lot* of trouble with Part F of the homework: implementing `featurize`, which entailed computing a matrix of word frequencies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was explained that the number of rows of this matrix should correspond to the number of documents (books), and the number of columns correspond with the number of unique words across all the documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the dimensions of this matrix took two steps:\n",
    " 1. Iterate through the number of books/documents.\n",
    " 2. Combine all the words from the books/documents together, and count how many *unique* words there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def featurize(*books):\n",
    "    rows = len(books)  # This is your number of rows.\n",
    "    \n",
    "    vocabulary = global_vocabulary(books)  # Your function from Part E!\n",
    "    cols = len(vocabulary)  # This is your number of columns.\n",
    "    \n",
    "    feature_matrix = np.zeros(shape = (rows, cols))  # Here's your feature matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Of course, that code isn't complete: you still have to fill in the features, which are the word counts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do this, you can use your `word_counts` function from Part B. But you have to build a word count dictionary for *each book*, *one at a time.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have the word count dictionary for a book, you'll then have to loop through the words *in that book* and add the counts to the right column of the feature matrix you built."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def featurize(*books):\n",
    "    rows = len(books)  # This is your number of rows.\n",
    "    \n",
    "    vocabulary = global_vocabulary(books)  # Your function from Part E!\n",
    "    cols = len(vocabulary)  # This is your number of columns.\n",
    "    \n",
    "    feature_matrix = np.zeros(shape = (rows, cols))  # Here's your feature matrix.\n",
    "    \n",
    "    # Loop through the books, generating a word count dictionary for each.\n",
    "    for row_index, book in enumerate(books):  # enumerate() is very helpful here\n",
    "        wc = word_counts(book)\n",
    "        for word, count in wc.items():  # This loops through the words IN THIS BOOK.\n",
    "            \n",
    "            # Which column does this go in?\n",
    "            col_index = vocabulary.index(word)\n",
    "            \n",
    "            # Insert the count!\n",
    "            feature_matrix[row_index, col_index] = count\n",
    "            \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember the point of *optional/default* arguments: they're *optional*, so you don't have to specify them when you call a function; if you don't, they take on a pre-defined *default* value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Q1, Part C, when calling the `skimage.measure.label()` function, some people were specifying all the default arguments with their default values. This is perfectly ok, but just know that's a lot of typing you don't actually have to do. Whatever default value was specified in the documentation on the website is the value that argument takes if you don't provide it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### From A10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bias/Variance trade-off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a critical concept to understand. Remember what these two quantities are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - *Bias* refers to how far the average estimate of the model is from the true, underlying average\n",
    " - *Variance* refers to how far around this average the predictions of the model spread out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An ideal model has small bias and small variance. In practice it's usually impossible to achieve this, as decreasing one tends to increase the other: you can either make consistent predictions that are off from the true average (high bias, low variance), or scattered predictions that tend to average out to the true value (low bias, high variance)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Every model you ever create will reflect this interplay, explicitly or not. K-nearest neighbors is a great example because this interplay is very explicit as you vary $k$, the neighborhood size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - When $k$ is small, this means you're using a very small neighborhood of data points to predict a new one. You can imagine how this could give rise to vastly different predictions in different neighborhoods, since the neighborhood used to make a prediction is so small. However, this also means the prediction will be extremely localized and probably more accurate. This is **low bias, but high variance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - When $k$ is large, this means you're averaging the votes of a massive neighborhood of data--possibly even the entire dataset. Therefore, it doesn't really matter where the new data point is landing, since its \"neighborhood\" is pretty much the entire universe, so the prediction will be the same no matter what. This is **high bias, low variance.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Support Vector Machines (SVMs) also embody this bias-variance tradeoff, but much less explicitly. Their internal algorithm is so much more sophisticated than KNNs that there is no one variable you can use to modulate the trade-off; instead, it's largely hard-coded into SVMs: they're designed to have **high bias, but low variance**. Thhis hard-coding may seem like a disadvantage, but it really depends on the situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#### Cross-validate all the things!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation is an immensely valuable tool that is central to the design of any predictive model. The goal of cross-validation is to estimate how good your model is at *generalizing* to new data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It works by taking your data and splitting it into *folds*: most of these folds are used to train the model, and the last fold is used to test it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the homework, some submission didn't abide by this: they trained on the whole dataset, then tested on the whole dataset. **This is NOT cross-validation:** the training and testing subsets **MUST** be mututally exclusive: for example, use the first 75% of the data as training, and the last 25% as testing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Other Questions from the Google Hangouts Review Session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Please make sure to fill out the course evaluations!\n",
    "\n",
    "http://eval.franklin.uga.edu/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Good luck!\n",
    "\n",
    "![goodluck](FinalReview/b89bcdae50a2fc8ee595c4ebc6b47db6e07a9aee5d1147a204d01eacf949341b.jpg)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
